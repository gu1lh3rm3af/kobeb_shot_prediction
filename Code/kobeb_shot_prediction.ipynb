{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad19844b-9c22-40c5-9c70-33ca3579f471",
   "metadata": {},
   "source": [
    "# Kobe Bryant - Análise Preditiva de Acertos "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75870c51-86b2-4388-8ed9-28ca0d3af769",
   "metadata": {},
   "source": [
    "#### Importação das bibliotecas e dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "378a8cf8-11ad-44f9-a254-dfa2bb32d11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pycaret.classification as pc\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import os\n",
    "import requests\n",
    "from sklearn import linear_model, preprocessing, metrics, model_selection\n",
    "from mlflow.models.signature import infer_signature\n",
    "from mlflow.tracking import MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c0c0996-1a54-4f72-a3a5-dda7dc60671b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muda o diretório de trabalho\n",
    "os.chdir('/Users\\Guilherme\\OneDrive - Firjan\\Estudo\\Infnet\\Módulo_2\\Projeto\\kobeb_shot_prediction\\Code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "68ed503b-3718-40c5-8881-3942929e867f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30697, 25)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('..\\Data\\kobe_dataset.csv', sep=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cccfed55-97f6-4b9c-9d52-e5225ff4ecf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25697, 25)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full = pd.read_csv('..\\Data\\kobe_dataset.csv', sep=',')\n",
    "df = df_full.dropna(subset=['shot_made_flag'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd98a8b0-02d8-4fc8-a56d-26fba5b996b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_model_name = 'modelo_kobeb_shots'\n",
    "min_precision = 0.6\n",
    "model_version = -1 # recuperar a ultima versao\n",
    "nexamples = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d81fc0f-b5cf-48ea-aae1-4b23c03b0d7a",
   "metadata": {},
   "source": [
    "#### Preparação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29211302-d47f-4fb0-ba39-371bf40059cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar o sqlite como repositório\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
    "\n",
    "experiment_name = 'kobe_shot_prediction'\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "if experiment is None:\n",
    "    experiment_id = mlflow.create_experiment(experiment_name)\n",
    "    experiment = mlflow.get_experiment(experiment_id)\n",
    "experiment_id = experiment.experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "381a656f-141b-4780-af55-52259b07757f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Bases de Dados ==\n",
      "data_dev (16228, 7)\n",
      "data_operation (4057, 7)\n",
      "data_novelty (5412, 7)\n",
      "Columns: Index(['lat', 'lon', 'minutes_remaining', 'period', 'playoffs',\n",
      "       'shot_distance', 'shot_made_flag'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Run de Preparação de dados\n",
    "# Paramentros: features,\n",
    "# Metricas: SHAPE de cada base de dados, porcentagem de teste\n",
    "# Artefatos: nenhum\n",
    "\n",
    "\n",
    "features = ['lat','lon','minutes_remaining', 'period', 'playoffs', 'shot_distance']\n",
    "target_col = 'shot_made_flag'\n",
    "test_size = 0.2\n",
    "\n",
    "with mlflow.start_run(experiment_id=experiment_id, run_name = 'PreparacaoDados'):\n",
    "    \n",
    "    df_full = pd.read_csv('..\\Data\\kobe_dataset.csv', sep=',')\n",
    "    df = df_full.dropna(subset=['shot_made_flag'])\n",
    "    df_2pt = df[df['shot_type'] == '2PT Field Goal'].copy()\n",
    "    \n",
    "        # Salvando os arquivos do dados filtrados para cestas de 2 pontos\n",
    "    df_2pt.to_parquet('../Data/processed/data_filtered.parquet')\n",
    "    \n",
    "    \n",
    "        # Separar parte para compor a base de operacao\n",
    "    Y  = df_2pt[target_col]\n",
    "    df_2pt = df_2pt[features]\n",
    "    data_train, data_test, ytrain, ytest = model_selection.train_test_split(df_2pt, Y, test_size=0.2, stratify=Y)\n",
    "    data_train = pd.merge(data_train, ytrain, left_index=True, right_index=True)\n",
    "    data_test = pd.merge(data_test, ytest, left_index=True, right_index=True)\n",
    "    \n",
    "        # Salvando arquivos de treino e de teste\n",
    "    data_train.to_parquet('../Data/operalization/data_train.parquet')\n",
    "    data_test.to_parquet('../Data/operalization/data_test.parquet')\n",
    "    \n",
    "        # Base com arremessos de 3pt\n",
    "    data_novelty = df[df['shot_type'] == '3PT Field Goal'].copy()\n",
    "    data_novelty = data_novelty[features + [target_col]]\n",
    "    \n",
    "        # Salvando os arquivos do dados das cestas de 3 pontos\n",
    "    data_novelty.to_parquet('../Data/novelty/data_novelty.parquet')\n",
    "     \n",
    "         # Log dos paramentros e métricas do modelo\n",
    "    mlflow.log_param(\"features\", features)\n",
    "    mlflow.log_param(\"percent_teste\", test_size)\n",
    "    mlflow.log_metric(\"data_dev\", data_train.shape[0])\n",
    "    mlflow.log_metric(\"data_operation\", data_test.shape[0])\n",
    "    mlflow.log_metric(\"data_novelty\", data_novelty.shape[0])\n",
    "\n",
    "mlflow.end_run()\n",
    "\n",
    "print('== Bases de Dados ==')\n",
    "print(f'data_dev {data_train.shape}')\n",
    "print(f'data_operation {data_test.shape}')\n",
    "print(f'data_novelty {data_novelty.shape}')\n",
    "print(f'Columns: {data_train.columns}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e56f6ae-fa9b-4a37-a4d5-f7fe5bf6f496",
   "metadata": {},
   "source": [
    "#### Treinamento dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6321b54-cb32-454d-91c9-47556ef8fda4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_1152f_row19_col1, #T_1152f_row29_col1, #T_1152f_row31_col1, #T_1152f_row42_col1, #T_1152f_row44_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_1152f_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_1152f_row0_col0\" class=\"data row0 col0\" >session_id</td>\n",
       "      <td id=\"T_1152f_row0_col1\" class=\"data row0 col1\" >41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_1152f_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_1152f_row1_col1\" class=\"data row1 col1\" >shot_made_flag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_1152f_row2_col0\" class=\"data row2 col0\" >Target Type</td>\n",
       "      <td id=\"T_1152f_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_1152f_row3_col0\" class=\"data row3 col0\" >Label Encoded</td>\n",
       "      <td id=\"T_1152f_row3_col1\" class=\"data row3 col1\" >0.0: 0, 1.0: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_1152f_row4_col0\" class=\"data row4 col0\" >Original Data</td>\n",
       "      <td id=\"T_1152f_row4_col1\" class=\"data row4 col1\" >(16228, 7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_1152f_row5_col0\" class=\"data row5 col0\" >Missing Values</td>\n",
       "      <td id=\"T_1152f_row5_col1\" class=\"data row5 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_1152f_row6_col0\" class=\"data row6 col0\" >Numeric Features</td>\n",
       "      <td id=\"T_1152f_row6_col1\" class=\"data row6 col1\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_1152f_row7_col0\" class=\"data row7 col0\" >Categorical Features</td>\n",
       "      <td id=\"T_1152f_row7_col1\" class=\"data row7 col1\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_1152f_row8_col0\" class=\"data row8 col0\" >Ordinal Features</td>\n",
       "      <td id=\"T_1152f_row8_col1\" class=\"data row8 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_1152f_row9_col0\" class=\"data row9 col0\" >High Cardinality Features</td>\n",
       "      <td id=\"T_1152f_row9_col1\" class=\"data row9 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_1152f_row10_col0\" class=\"data row10 col0\" >High Cardinality Method</td>\n",
       "      <td id=\"T_1152f_row10_col1\" class=\"data row10 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_1152f_row11_col0\" class=\"data row11 col0\" >Transformed Train Set</td>\n",
       "      <td id=\"T_1152f_row11_col1\" class=\"data row11 col1\" >(16228, 23)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_1152f_row12_col0\" class=\"data row12 col0\" >Transformed Test Set</td>\n",
       "      <td id=\"T_1152f_row12_col1\" class=\"data row12 col1\" >(4057, 23)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_1152f_row13_col0\" class=\"data row13 col0\" >Shuffle Train-Test</td>\n",
       "      <td id=\"T_1152f_row13_col1\" class=\"data row13 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_1152f_row14_col0\" class=\"data row14 col0\" >Stratify Train-Test</td>\n",
       "      <td id=\"T_1152f_row14_col1\" class=\"data row14 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_1152f_row15_col0\" class=\"data row15 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_1152f_row15_col1\" class=\"data row15 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_1152f_row16_col0\" class=\"data row16 col0\" >Fold Number</td>\n",
       "      <td id=\"T_1152f_row16_col1\" class=\"data row16 col1\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_1152f_row17_col0\" class=\"data row17 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_1152f_row17_col1\" class=\"data row17 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_1152f_row18_col0\" class=\"data row18 col0\" >Use GPU</td>\n",
       "      <td id=\"T_1152f_row18_col1\" class=\"data row18 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_1152f_row19_col0\" class=\"data row19 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_1152f_row19_col1\" class=\"data row19 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_1152f_row20_col0\" class=\"data row20 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_1152f_row20_col1\" class=\"data row20 col1\" >kobe_shot_prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_1152f_row21_col0\" class=\"data row21 col0\" >USI</td>\n",
       "      <td id=\"T_1152f_row21_col1\" class=\"data row21 col1\" >26fb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_1152f_row22_col0\" class=\"data row22 col0\" >Imputation Type</td>\n",
       "      <td id=\"T_1152f_row22_col1\" class=\"data row22 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_1152f_row23_col0\" class=\"data row23 col0\" >Iterative Imputation Iteration</td>\n",
       "      <td id=\"T_1152f_row23_col1\" class=\"data row23 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_1152f_row24_col0\" class=\"data row24 col0\" >Numeric Imputer</td>\n",
       "      <td id=\"T_1152f_row24_col1\" class=\"data row24 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "      <td id=\"T_1152f_row25_col0\" class=\"data row25 col0\" >Iterative Imputation Numeric Model</td>\n",
       "      <td id=\"T_1152f_row25_col1\" class=\"data row25 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "      <td id=\"T_1152f_row26_col0\" class=\"data row26 col0\" >Categorical Imputer</td>\n",
       "      <td id=\"T_1152f_row26_col1\" class=\"data row26 col1\" >constant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "      <td id=\"T_1152f_row27_col0\" class=\"data row27 col0\" >Iterative Imputation Categorical Model</td>\n",
       "      <td id=\"T_1152f_row27_col1\" class=\"data row27 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
       "      <td id=\"T_1152f_row28_col0\" class=\"data row28 col0\" >Unknown Categoricals Handling</td>\n",
       "      <td id=\"T_1152f_row28_col1\" class=\"data row28 col1\" >least_frequent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
       "      <td id=\"T_1152f_row29_col0\" class=\"data row29 col0\" >Normalize</td>\n",
       "      <td id=\"T_1152f_row29_col1\" class=\"data row29 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
       "      <td id=\"T_1152f_row30_col0\" class=\"data row30 col0\" >Normalize Method</td>\n",
       "      <td id=\"T_1152f_row30_col1\" class=\"data row30 col1\" >minmax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row31\" class=\"row_heading level0 row31\" >31</th>\n",
       "      <td id=\"T_1152f_row31_col0\" class=\"data row31 col0\" >Transformation</td>\n",
       "      <td id=\"T_1152f_row31_col1\" class=\"data row31 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row32\" class=\"row_heading level0 row32\" >32</th>\n",
       "      <td id=\"T_1152f_row32_col0\" class=\"data row32 col0\" >Transformation Method</td>\n",
       "      <td id=\"T_1152f_row32_col1\" class=\"data row32 col1\" >yeo-johnson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row33\" class=\"row_heading level0 row33\" >33</th>\n",
       "      <td id=\"T_1152f_row33_col0\" class=\"data row33 col0\" >PCA</td>\n",
       "      <td id=\"T_1152f_row33_col1\" class=\"data row33 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row34\" class=\"row_heading level0 row34\" >34</th>\n",
       "      <td id=\"T_1152f_row34_col0\" class=\"data row34 col0\" >PCA Method</td>\n",
       "      <td id=\"T_1152f_row34_col1\" class=\"data row34 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row35\" class=\"row_heading level0 row35\" >35</th>\n",
       "      <td id=\"T_1152f_row35_col0\" class=\"data row35 col0\" >PCA Components</td>\n",
       "      <td id=\"T_1152f_row35_col1\" class=\"data row35 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row36\" class=\"row_heading level0 row36\" >36</th>\n",
       "      <td id=\"T_1152f_row36_col0\" class=\"data row36 col0\" >Ignore Low Variance</td>\n",
       "      <td id=\"T_1152f_row36_col1\" class=\"data row36 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row37\" class=\"row_heading level0 row37\" >37</th>\n",
       "      <td id=\"T_1152f_row37_col0\" class=\"data row37 col0\" >Combine Rare Levels</td>\n",
       "      <td id=\"T_1152f_row37_col1\" class=\"data row37 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row38\" class=\"row_heading level0 row38\" >38</th>\n",
       "      <td id=\"T_1152f_row38_col0\" class=\"data row38 col0\" >Rare Level Threshold</td>\n",
       "      <td id=\"T_1152f_row38_col1\" class=\"data row38 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row39\" class=\"row_heading level0 row39\" >39</th>\n",
       "      <td id=\"T_1152f_row39_col0\" class=\"data row39 col0\" >Numeric Binning</td>\n",
       "      <td id=\"T_1152f_row39_col1\" class=\"data row39 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row40\" class=\"row_heading level0 row40\" >40</th>\n",
       "      <td id=\"T_1152f_row40_col0\" class=\"data row40 col0\" >Remove Outliers</td>\n",
       "      <td id=\"T_1152f_row40_col1\" class=\"data row40 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row41\" class=\"row_heading level0 row41\" >41</th>\n",
       "      <td id=\"T_1152f_row41_col0\" class=\"data row41 col0\" >Outliers Threshold</td>\n",
       "      <td id=\"T_1152f_row41_col1\" class=\"data row41 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row42\" class=\"row_heading level0 row42\" >42</th>\n",
       "      <td id=\"T_1152f_row42_col0\" class=\"data row42 col0\" >Remove Multicollinearity</td>\n",
       "      <td id=\"T_1152f_row42_col1\" class=\"data row42 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row43\" class=\"row_heading level0 row43\" >43</th>\n",
       "      <td id=\"T_1152f_row43_col0\" class=\"data row43 col0\" >Multicollinearity Threshold</td>\n",
       "      <td id=\"T_1152f_row43_col1\" class=\"data row43 col1\" >0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row44\" class=\"row_heading level0 row44\" >44</th>\n",
       "      <td id=\"T_1152f_row44_col0\" class=\"data row44 col0\" >Remove Perfect Collinearity</td>\n",
       "      <td id=\"T_1152f_row44_col1\" class=\"data row44 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row45\" class=\"row_heading level0 row45\" >45</th>\n",
       "      <td id=\"T_1152f_row45_col0\" class=\"data row45 col0\" >Clustering</td>\n",
       "      <td id=\"T_1152f_row45_col1\" class=\"data row45 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row46\" class=\"row_heading level0 row46\" >46</th>\n",
       "      <td id=\"T_1152f_row46_col0\" class=\"data row46 col0\" >Clustering Iteration</td>\n",
       "      <td id=\"T_1152f_row46_col1\" class=\"data row46 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row47\" class=\"row_heading level0 row47\" >47</th>\n",
       "      <td id=\"T_1152f_row47_col0\" class=\"data row47 col0\" >Polynomial Features</td>\n",
       "      <td id=\"T_1152f_row47_col1\" class=\"data row47 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row48\" class=\"row_heading level0 row48\" >48</th>\n",
       "      <td id=\"T_1152f_row48_col0\" class=\"data row48 col0\" >Polynomial Degree</td>\n",
       "      <td id=\"T_1152f_row48_col1\" class=\"data row48 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row49\" class=\"row_heading level0 row49\" >49</th>\n",
       "      <td id=\"T_1152f_row49_col0\" class=\"data row49 col0\" >Trignometry Features</td>\n",
       "      <td id=\"T_1152f_row49_col1\" class=\"data row49 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row50\" class=\"row_heading level0 row50\" >50</th>\n",
       "      <td id=\"T_1152f_row50_col0\" class=\"data row50 col0\" >Polynomial Threshold</td>\n",
       "      <td id=\"T_1152f_row50_col1\" class=\"data row50 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row51\" class=\"row_heading level0 row51\" >51</th>\n",
       "      <td id=\"T_1152f_row51_col0\" class=\"data row51 col0\" >Group Features</td>\n",
       "      <td id=\"T_1152f_row51_col1\" class=\"data row51 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row52\" class=\"row_heading level0 row52\" >52</th>\n",
       "      <td id=\"T_1152f_row52_col0\" class=\"data row52 col0\" >Feature Selection</td>\n",
       "      <td id=\"T_1152f_row52_col1\" class=\"data row52 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row53\" class=\"row_heading level0 row53\" >53</th>\n",
       "      <td id=\"T_1152f_row53_col0\" class=\"data row53 col0\" >Feature Selection Method</td>\n",
       "      <td id=\"T_1152f_row53_col1\" class=\"data row53 col1\" >classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row54\" class=\"row_heading level0 row54\" >54</th>\n",
       "      <td id=\"T_1152f_row54_col0\" class=\"data row54 col0\" >Features Selection Threshold</td>\n",
       "      <td id=\"T_1152f_row54_col1\" class=\"data row54 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row55\" class=\"row_heading level0 row55\" >55</th>\n",
       "      <td id=\"T_1152f_row55_col0\" class=\"data row55 col0\" >Feature Interaction</td>\n",
       "      <td id=\"T_1152f_row55_col1\" class=\"data row55 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row56\" class=\"row_heading level0 row56\" >56</th>\n",
       "      <td id=\"T_1152f_row56_col0\" class=\"data row56 col0\" >Feature Ratio</td>\n",
       "      <td id=\"T_1152f_row56_col1\" class=\"data row56 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row57\" class=\"row_heading level0 row57\" >57</th>\n",
       "      <td id=\"T_1152f_row57_col0\" class=\"data row57 col0\" >Interaction Threshold</td>\n",
       "      <td id=\"T_1152f_row57_col1\" class=\"data row57 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row58\" class=\"row_heading level0 row58\" >58</th>\n",
       "      <td id=\"T_1152f_row58_col0\" class=\"data row58 col0\" >Fix Imbalance</td>\n",
       "      <td id=\"T_1152f_row58_col1\" class=\"data row58 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1152f_level0_row59\" class=\"row_heading level0 row59\" >59</th>\n",
       "      <td id=\"T_1152f_row59_col0\" class=\"data row59 col0\" >Fix Imbalance Method</td>\n",
       "      <td id=\"T_1152f_row59_col1\" class=\"data row59 col1\" >SMOTE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x283f1bd9708>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Runs de setup\n",
    "# Parametros: none\n",
    "# Métricas: none\n",
    "# Artefatos: none\n",
    "\n",
    "data_train = pd.read_parquet('../Data/operalization/data_train.parquet')\n",
    "data_test = pd.read_parquet('../Data/operalization/data_test.parquet')\n",
    "\n",
    "reg = pc.setup(data=data_train,\n",
    "                target=target_col,\n",
    "                test_data=data_test,\n",
    "                preprocess=True,\n",
    "                normalize=True,\n",
    "                log_experiment = True,\n",
    "                log_plots = True,\n",
    "                experiment_name = experiment_name,\n",
    "                normalize_method='minmax',\n",
    "                transformation=True,\n",
    "                remove_multicollinearity=True,\n",
    "                multicollinearity_threshold=0.9,\n",
    "                fold_strategy='stratifiedkfold',\n",
    "                fold = 5,\n",
    "                silent = True,\n",
    "                session_id=41\n",
    "              )\n",
    "\n",
    "pc.add_metric('logloss', 'Log Loss', metrics.log_loss)\n",
    "\n",
    "# Log do run\n",
    "classification_plots = ['auc',\n",
    "                        'pr',\n",
    "                        'confusion_matrix',\n",
    "                        'threshold',\n",
    "                        'learning',\n",
    "                        'vc',\n",
    "                        'feature']\n",
    "\n",
    "\n",
    "\n",
    "while mlflow.active_run() != None:\n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b028a2e7-ec77-4e8c-8101-343a1d7690e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Saved\n"
     ]
    }
   ],
   "source": [
    "# Run de treinamento do modelo de regressão logística\n",
    "# Parâmetros: probability_threshold, cross_validation\n",
    "# Métricas: auto sklearn + logloss\n",
    "# Artefatos: plots\n",
    "\n",
    "probability_threshold = 0.6\n",
    "cross_validation = True\n",
    "\n",
    "with mlflow.start_run(experiment_id=experiment_id, run_name = 'Treinamento Lr'):\n",
    "        \n",
    "    model_name = 'lr'\n",
    "    best_model = pc.create_model(model_name,\n",
    "                                cross_validation = cross_validation, \n",
    "                                probability_threshold=probability_threshold)\n",
    "    \n",
    "    for plot_type in classification_plots:\n",
    "            print('=> Aplicando plot ', plot_type)\n",
    "            try:\n",
    "                artifact = pc.plot_model(best_model, plot=plot_type, save=True, use_train_data=False)\n",
    "                mlflow.log_artifact(artifact)\n",
    "            except:\n",
    "                print('=> Nao possivel plotar: ', plot_type )\n",
    "                continue\n",
    "    \n",
    "    pc.save_model(best_model, f'./{str(best_model.classifier).split(\"(\")[0]}') \n",
    "\n",
    "while mlflow.active_run() != None:\n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54c053fa-5b1d-4508-9467-357678975789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Saved\n"
     ]
    }
   ],
   "source": [
    "# Run de seleção e treinamento do segundo modelo de classificação\n",
    "# Parâmetros: probability_threshold, cross_validation\n",
    "# Métricas: auto sklearn + logloss\n",
    "# Artefatos: plots\n",
    "\n",
    "probability_threshold = 0.6\n",
    "cross_validation = True\n",
    "\n",
    "with mlflow.start_run(experiment_id=experiment_id, run_name = 'Treinamento 2º modelo'):\n",
    "\n",
    "    best_model = pc.compare_models(n_select = 1, sort='f1', include=['dt', 'svm'])\n",
    "\n",
    "    for plot_type in classification_plots:\n",
    "            print('=> Aplicando plot ', plot_type)\n",
    "            try:\n",
    "                artifact = pc.plot_model(best_model, plot=plot_type, save=True, use_train_data=False)\n",
    "                mlflow.log_artifact(artifact)\n",
    "            except:\n",
    "                print('=> Nao possivel plotar: ', plot_type )\n",
    "                continue\n",
    "    \n",
    "    pc.save_model(best_model, f'./{str(best_model).split(\"(\")[0]}') \n",
    "\n",
    "while mlflow.active_run() != None:\n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dec2df7-009d-468c-b559-75063b2a6b91",
   "metadata": {},
   "source": [
    "#### Aprovação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df21bfd1-7d3a-459e-ad52-65f89aca78d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Loaded\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_1a38a_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th class=\"col_heading level0 col8\" >Log Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_1a38a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_1a38a_row0_col0\" class=\"data row0 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_1a38a_row0_col1\" class=\"data row0 col1\" >0.5433</td>\n",
       "      <td id=\"T_1a38a_row0_col2\" class=\"data row0 col2\" >0.6030</td>\n",
       "      <td id=\"T_1a38a_row0_col3\" class=\"data row0 col3\" >0.0981</td>\n",
       "      <td id=\"T_1a38a_row0_col4\" class=\"data row0 col4\" >0.6419</td>\n",
       "      <td id=\"T_1a38a_row0_col5\" class=\"data row0 col5\" >0.1702</td>\n",
       "      <td id=\"T_1a38a_row0_col6\" class=\"data row0 col6\" >0.0499</td>\n",
       "      <td id=\"T_1a38a_row0_col7\" class=\"data row0 col7\" >0.0924</td>\n",
       "      <td id=\"T_1a38a_row0_col8\" class=\"data row0 col8\" >15.7753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x283f5d32b88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Aceito o modelo com precisão 0.6418918918918919 (min: 0.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'modelo_kobeb_shots' already exists. Creating a new version of this model...\n",
      "2022/04/23 20:18:27 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: modelo_kobeb_shots, version 3\n",
      "Created version '3' of model 'modelo_kobeb_shots'.\n"
     ]
    }
   ],
   "source": [
    "# Run de aprovação do modelo\n",
    "# Parâmetros: min_precision\n",
    "# Métricas: new_version, precision\n",
    "# Artefatos: None\n",
    "\n",
    "# Carrega o pipeline + model\n",
    "model_pipe = pc.load_model(f'./LogisticRegression')\n",
    "\n",
    "with mlflow.start_run(experiment_id=experiment_id, run_name = 'AprovacaoModelo'):\n",
    "    #pred_holdout = pc.predict_model(best_model)\n",
    "    pred_holdout = pc.predict_model(model_pipe)\n",
    "    pr = metrics.precision_score(pred_holdout[target_col], pred_holdout['Label'], pos_label='1.0')\n",
    "    if pr > min_precision:\n",
    "        print(f'=> Aceito o modelo com precisão {pr} (min: {min_precision})')\n",
    "        pred_holdout.to_parquet('modelo_kobebshot_teste.parquet')\n",
    "        # Assinatura do Modelo Inferida pelo MLFlow\n",
    "        model_features = list(data_train.drop(target_col, axis=1).columns)\n",
    "        inf_signature = infer_signature(data_train[model_features], model_pipe.predict(data_train))\n",
    "        # Exemplo de entrada para o MLmodel\n",
    "        input_example = {x: data_train[x].values[:nexamples] for x in model_features}\n",
    "        # Log do pipeline de modelagem do sklearn e registrar como uma nova versao\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=model_pipe,\n",
    "            artifact_path=\"sklearn-model\",\n",
    "            registered_model_name=registered_model_name,\n",
    "            signature = inf_signature,\n",
    "            input_example = input_example\n",
    "        )\n",
    "        # Criacao do cliente do servico MLFlow e atualizacao versao modelo\n",
    "        client = MlflowClient()\n",
    "        if model_version == -1:\n",
    "            model_version = client.get_latest_versions(registered_model_name)[-1].version\n",
    "        # Registrar o modelo como staging\n",
    "        client.transition_model_version_stage(\n",
    "            name=registered_model_name,\n",
    "            version=model_version, # Verificar com usuario qual versao\n",
    "            stage=\"Staging\"\n",
    "        )\n",
    "    else:\n",
    "        print(f'=> Rejeitado o modelo com precisão {pr} (min: {min_precision})')\n",
    "    \n",
    "    # LOG DE PARAMETROS DO MODELO\n",
    "    mlflow.log_param(\"precisao_minima\", min_precision)\n",
    "    \n",
    "    # LOG DE METRICAS GLOBAIS\n",
    "    mlflow.log_metric(\"new_version\", model_version)\n",
    "    mlflow.log_metric(\"precisao\", pr)\n",
    "\n",
    "while mlflow.active_run() != None:\n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba048fd-cfc8-40bd-9ba9-6993baa81f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#client.delete_model_version(name=registered_model_name, version=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a2c5c20-c053-482b-9af5-c7f73c626484",
   "metadata": {},
   "outputs": [],
   "source": [
    "#client.delete_registered_model(name=registered_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d157cc26-135f-4b89-a31d-4418d9b292a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "#!mlflow ui --backend-store-uri sqlite:///mlruns.db --port 5005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "738096d6-049e-45da-b05d-339eef433663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "os.environ['MLFLOW_TRACKING_URI'] = 'sqlite:///mlruns.db'\n",
    "!mlflow models serve -m \"models:/modelo_kobeb_shots/Staging\" --no-conda -p 5005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a3d59bb-f3c3-4be6-9966-6e8c49655bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "host = 'localhost'\n",
    "port = '5005'\n",
    "url = f'http://{host}:{port}/invocations'\n",
    "headers = {'Content-Type': 'application/json',}\n",
    "\n",
    "data_novelty = pd.read_parquet('../Data/novelty/data_novelty.parquet')\n",
    "\n",
    "http_data = data_novelty.drop(target_col,axis=1).to_json(orient='split')\n",
    "r = requests.post(url=url, headers=headers, data=http_data)\n",
    "\n",
    "#data_novelty.loc[:, 'operation_label'] = pd.read_json(r.text).values[:,0]\n",
    "\n",
    "#data_novelty.to_parquet('modelo_kobebshot_operacao.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d70c615-edae-48d6-9b87-bb8e1dd133ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [404]>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba38b78a-9b45-406f-8a6f-efcf7ae55314",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_21616/1346671572.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\GUILHE~1\\AppData\\Local\\Temp/ipykernel_21616/1346671572.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    $ curl http://127.0.0.1:5000/invocations -H 'Content-Type: application/json' -d http_data\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "$ curl http://127.0.0.1:5005/invocations -H 'Content-Type: application/json' -d http_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
